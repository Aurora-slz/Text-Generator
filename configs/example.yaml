input_file: "examples/data/amc23.jsonl"
output_file: "examples/data/amc23_synthesis.jsonl"
input_key: "problem"
output_key: "response"
algorithm: "QuestionSynthesis"

generator_type: "local"
configs:
  - device: "cuda" # device to run the model on
    model_path: "Qwen/Qwen2.5-0.5B-Instruct" # path to the local model
    n: 1 # number of generated sequences
    best_of: null  # best of sampling
    presence_penalty: 0  # presence penalty
    frequency_penalty: 0  # frequency penalty
    repetition_penalty: 1  # repetition penalty
    temperature: 1 # temperature for sampling
    top_p: 1 # top-p sampling
    top_k: -1 # top-k sampling
    min_p: 0 # minimum probability
    seed: null # random seed
    stop: null # stop sequence
    stop_token_ids: null # stop token ids
    ignore_eos: False
    max_tokens: 32
    min_tokens: 0
    logprobs: null
    prompt_logprobs: null
    detokenize: True
    skip_special_tokens: True
    spaces_between_special_tokens: True
    logits_processors: null
    include_stop_str_in_output: False
    truncate_prompt_tokens: null
    logit_bias: null # Dict[int,float]
    allowed_token_ids: null  # List[int]
    download_dir: "ckpr/models/"
    prompt: "You are a helpful assistant" #system prompt for the model

# input_file: "examples/data/amc23.jsonl"
# output_file: examples/data/amc23_diff_api.jsonl"
# input_key: "response"
# output_key: "solution"
# algorithm: "AnswerGenerater_reasoning"

# generator_type: "request"
# configs:
#   system_prompt: ""
#   input_key: "problem"
#   output_key: "response"
#   model_name: "gpt-4o-mini"
#   api_url: "http://123.129.219.111:3000/v1/chat/completions"
#   api_key: 'sk-bpQKw8OdWE1o8U2aDDw705dVa12iiMZv3wSzU9yXMUM7bNFd'
#   db_path: "/root/workspace/culfjk4p420c73amv510/herunming/Text-Generator/examples/db/amc23_db.json"
#   max_workers: 20
#   input_file: "examples/data/amc23.jsonl"
#   output_file: "examples/data/amc23_diff_api.jsonl"
#   generator_type: "request"